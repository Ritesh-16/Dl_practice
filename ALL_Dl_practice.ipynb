{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMFrg35saMYtUZph5r1JbYe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Practical 1 Write a program and preprocess the data in python.\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","# Your dataset\n","data = {\n","'Country': ['India', 'Sri Lanka', 'China', 'Sri Lanka', 'China', 'India', 'Sri Lanka', 'India', 'China', 'India', 'Sri Lanka', 'China', 'India', 'India', 'Sri Lanka'],\n","'Age': [34, 22, 31, 29, 55, 24, 28, None, 51, 44, 21, 25, 33, 42, 33],\n","'Salary': [92000, 25000, 74000, None, 98000, 30000, 40000, 60000, 89000, 78000, 20000, 30000, 45000, 65000, 22000],\n","'Purchased': ['Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No']\n","}\n","df = pd.DataFrame(data)\n","# Separate numerical and categorical columns\n","numeric_features = ['Age', 'Salary']\n","categorical_features = ['Country']\n","# Define preprocessing steps\n","numeric_transformer = Pipeline(steps=[\n","('imputer', SimpleImputer(strategy='mean')),\n","('scaler', StandardScaler())])\n","categorical_transformer = Pipeline(steps=[\n","('imputer', SimpleImputer(strategy='most_frequent')),\n","('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n","# Combine preprocessing steps\n","preprocessor = ColumnTransformer(\n","transformers=[('num', numeric_transformer, numeric_features),\n","('cat', categorical_transformer, categorical_features)])\n","# Apply preprocessing to the data\n","preprocessed_data = preprocessor.fit_transform(df)\n","# Get feature names after one-hot encoding\n","feature_names = numeric_features + list(preprocessor.named_transformers_['cat']\n",".named_steps['onehot']\n",".get_feature_names_out(categorical_features))\n","# Convert preprocessed data back to a DataFrame\n","preprocessed_df = pd.DataFrame(preprocessed_data, columns=feature_names)\n","print(preprocessed_df)\n","#Preprocessing the data\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# Assuming you have your preprocessed data in preprocessed_df\n","# Visualizing Age distribution\n","plt.figure(figsize=(8, 6))\n","sns.histplot(preprocessed_df['Age'], bins=20, kde=True, color='skyblue')\n","plt.title('Distribution of Age')\n","plt.xlabel('Age')\n","plt.ylabel('Frequency')\n","plt.show()\n","# Visualizing Salary distribution\n","plt.figure(figsize=(8, 6))\n","sns.histplot(preprocessed_df['Salary'], bins=20, kde=True, color='salmon')\n","plt.title('Distribution of Salary')\n","plt.xlabel('Salary')\n","plt.ylabel('Frequency')\n","plt.show()\n","# Visualizing relationship between Age and Salary\n","plt.figure(figsize=(8, 6))\n","sns.scatterplot(x='Age', y='Salary', data=preprocessed_df, color='green')\n","plt.title('Relationship between Age and Salary')\n","plt.xlabel('Age')\n","plt.ylabel('Salary')\n","plt.show()\n","# Visualizing categorical data (Country after one-hot encoding)\n","country_columns = [col for col in preprocessed_df.columns if 'Country' in col]\n","country_data = preprocessed_df[country_columns]\n","plt.figure(figsize=(10, 6))\n","sns.countplot(data=country_data)\n","plt.title('Count of Countries')\n","plt.xlabel('Country')\n","plt.ylabel('Count')\n","plt.show()"],"metadata":{"id":"KzFffDCexBuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Practical 2 Write a program to demonstrate various operations related to tensor, matrix & vector.\n","\n","import numpy as np\n","scalar=5\n","tensor_1d=np.array([1,2,3])\n","tensor_2d=np.array([[1,2,3],[4,5,6],[7,8,9]])\n","add=np.add([1,2,3],[4,5,6])\n","mul=np.multiply([1,2,3],[1,2,3])\n","sub=np.subtract([2,1,2],[7,8,6])\n","transpose=np.transpose([[1,2,3],[4,5,6]])\n","dot=np.dot([1,2,3],[4,5,6])\n","zeros=np.zeros(4)\n","unit=np.eye(4)\n","unit\n","\n","import tensorflow as tf\n","m=tf.constant([[1,2,3],[4,5,6],[7,8,9]], shape=(3,3))\n","print(m)\n","\n","n=tf.constant([[10,20,30],[40,50,60],[70,80,90]],shape=(3,3))\n","print(n)\n","\n","add1=tf.add(m,n)\n","add1\n","\n","mul1=tf.multiply(n,m)\n","mul1\n","\n","mat=tf.matmul(m,n)\n","mat\n","\n","a=tf.zeros([3,3])\n","a\n","\n","b=tf.zeros([3,3])\n","\n","print(tf.reduce_max(a))\n","print(tf.reduce_max(b))\n","\n","print(tf.argmax(a))\n","\n","a=tf.ones([3,3])\n","a\n","tf.nn.softmax(a)\n","\n","A=tf.constant([[1,2],[3,4]])\n","B=tf.reshape(A,[4,1])\n","B\n","\n","a=tf.range(3,19,3)\n","a\n","\n","tensor=tf.constant([[1,2,3],[4,5,6]])\n","tf.zeros_like(tensor)\n","\n","tf.random.shuffle(tensor,seed=2,name=None)\n"],"metadata":{"id":"P98W3nSmxBkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Practical 3 Perfrom the following matrix operation in python:\n","# 1. Finding eigen values and eigen vectors\n","# 2. Check for linear denpendent and linear independent\n","# 3. Perform matrix transpose\n","# 4. Perform diagnonal martix\n","# 5. Perform triangular marix\n","# 6. Perform orthogonal matrix using numpy modules\n","\n","#1. Finding eigen values and eigen vectors\n","import numpy as np\n","matrix_a=np.array([[4,6,6],[1,3,2],[-1,-4,-3]])\n","#finding eigen values and eigenvectors\n","eigen_values,eigen_vectors=np.linalg.eig(matrix_a)\n","eigen_values,eigen_vectors\n","#checking for Linear Independence\n","rank = np.linalg.matrix_rank(matrix_a)\n","rows,columns=matrix_a.shape\n","if rank==min(rows,columns):\n","  print(\"Independent\")\n","else:\n","  print(\"Dependent\")\n","\n","#transpose\n","np.transpose(matrix_a)\n","\n","#diagonal matrix check\n","if sum(np.diag(matrix_a))==np.sum(matrix_a):\n","  print(\"Diagonal Matrix\")\n","else:\n","  print(\"Not Diagonal\")\n","\n","#triangular matrix\n","if np.allclose(np.triu(matrix_a), matrix_a):\n","    print(\"The matrix is upper triangular.\")\n","elif np.allclose(np.tril(matrix_a), matrix_a):\n","    print(\"The matrix is lower triangular.\")\n","else:\n","    print(\"The matrix is not triangular.\")\n","\n","#orthogonal matrix\n","matrix_a=[[0,1],[-1,0]]\n","product=np.dot(matrix_a,np.transpose(matrix_a))\n","unit_matrix=np.eye(len(matrix_a))\n","len(matrix_a)\n","if np.allclose(product,unit_matrix):\n","  print(\"Orthogonal\")\n","else:\n","  print(\"Not Orthogonal\")\n"],"metadata":{"id":"HGiGEpi7xBYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDxbn_8toB2R"},"outputs":[],"source":["#Practical 4 : Solve the EXOR problem using Deep learning\n","\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import numpy as np\n","# Define the XOR data\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","Y = np.array([[0], [1], [1], [0]])\n","# Create a deep feed-forward neural network\n","model = Sequential()\n","model.add(Dense(8, input_dim=2, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","# Train the model\n","model.fit(X, Y, epochs=100, verbose=2)\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X, Y)\n","print(f'\\nLoss: {loss}, Accuracy: {accuracy}')\n","# Make predictions\n","predictions = model.predict(X)\n","rounded_predictions = np.round(predictions)\n","print('Predictions:', rounded_predictions.flatten())"]},{"cell_type":"code","source":["#Practical 5:Performing Convolutional operation using CNN\n","from keras.layers import Convolution2D, MaxPooling2D, Activation\n","from keras.models import Sequential\n","from numpy import asarray\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","#Loading And Dispaly Image\n","img =cv2.imread('/content/images (1).jpg',cv2.IMREAD_GRAYSCALE)\n","plt.imshow(img,cmap='gray')\n","plt.show()\n","\n","#Checking Image shape\n","img.shape\n","\n","#Reshaping image Batch\n","img_batch=img.reshape(1,img.shape[0],img.shape[1],1)\n","img_batch\n","\n","#Accessing Image batch shape\n","img_batch.shape\n","\n","#Defining Sequential Model\n","img_batch.shape[1:]\n","model=Sequential()\n","\n","#Adding Convolution layer\n","model.add(Convolution2D(1,(15,15), padding='valid',input_shape=img_batch.shape[1:]))\n","\n","#printing model summary\n","model.summary()\n","\n","#Predicting with model\n","conv_img=model.predict(img_batch)\n","\n","#Checking Predicted iamge shape\n","conv_img.shape\n","\n","#Reshaping predicted iamge for\n","conv_img_show=conv_img.reshape(conv_img.shape[1],conv_img.shape[2])\n","plt.imshow(conv_img_show,cmap=\"gray\")\n","plt.show()\n","\n","\n","#Again with some changes\n","img_batch.shape[1:]\n","model2=Sequential()\n","\n","model2.add(Convolution2D(1,(15,15), padding='valid',input_shape=img_batch.shape[1:]))\n","model2.add(Activation('relu'))\n","\n","conv_img=model2.predict(img_batch)\n","conv_img.shape\n","conv_img_show=conv_img.reshape(conv_img.shape[1],conv_img.shape[2])\n","plt.imshow(conv_img_show,cmap=\"gray\")\n","plt.show()\n","\n","#\n","img_batch.shape[1:]\n","model3=Sequential()\n","model3.add(Convolution2D(1,(15,15), padding='valid',input_shape=img_batch.shape[1:]))\n","\n","model3.add(Activation('relu'))\n","model3.add(MaxPooling2D(pool_size=(2,2)))\n","conv_img=model3.predict(img_batch)\n","conv_img.shape\n","conv_img_show=conv_img.reshape(conv_img.shape[1],conv_img.shape[2])\n","plt.imshow(conv_img_show,cmap=\"gray\")\n","plt.show()\n","\n","#model 3 defining sequential model\n","img_batch.shape[1:]\n","model2=Sequential()\n","#convutional layer\n","model2.add(Convolution2D(1,(3,3),padding='valid',input_shape=img_batch.shape[1:]))\n","#random weight initialization\n","model2.add(Activation('relu'))\n","#predicting with model2\n","conv_img=model2.predict(img_batch)\n","#checking\n","conv_img.shape\n","#reshaping predicted image for display\n","conv_img_show = conv_img.reshape(conv_img.shape[1], conv_img.shape[2])\n","plt.imshow(conv_img_show, cmap='gray')\n","plt.show()\n","\n","\n","#model4\n","img_batch.shape[1:]\n","model4=Sequential()\n","model4.add(Convolution2D(1,(15,15),padding='valid',input_shape=img_batch.shape[1:]))\n","#random weight initialization\n","model4.add(Activation('relu'))\n","model4.add(MaxPooling2D(pool_size=(2,2)))\n","#predicting with model2\n","conv_img=model4.predict(img_batch)\n","#checking\n","conv_img.shape\n","#reshaping predicted image for display\n","conv_img_show = conv_img.reshape(conv_img.shape[1], conv_img.shape[2])\n","plt.imshow(conv_img_show, cmap='gray')\n","plt.show()"],"metadata":{"id":"YGm_VScDqQ6R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Practical 6 : Write a program to implement convolution with various layers\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras.datasets import fashion_mnist\n","from keras.layers import Dense,Conv2D,Dropout,MaxPooling2D,Flatten\n","from keras.models import Sequential\n","\n","fashion_data=fashion_mnist.load_data()\n","(x_train,y_train),(x_test,y_test)=fashion_data\n","x_train,x_validate=x_train[:50000],x_train[50000:]\n","y_train,y_validate=y_train[:50000],y_train[50000:]\n","\n","class_name=[\"T-Shirt/Top\",\"Trousers\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankleboot\"]\n","model=Sequential([\n","    Conv2D(64,3,activation=\"relu\",padding=\"same\",input_shape=[28,28,1]),\n","    MaxPooling2D(2),\n","    Dense(22,activation=\"relu\"),\n","    Dropout(0.2),\n","    Flatten(),\n","    Dense(10,activation=\"softmax\")\n","])\n","model.compile(loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'],optimizer=\"adam\")\n","output=model.fit(x_train,y_train,epochs=2,steps_per_epoch=5,validation_data=(x_validate,y_validate))\n","#increase epochs to 4 or something more the epochs more the time\n","\n","#bhavesh\n","import tensorflow as tf\n","from tensorflow import keras\n","# Load Fashion MNIST dataset\n","fashion_mnist = keras.datasets.fashion_mnist\n","(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()\n","# Normalize the data\n","x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n","# Split training set into training and validation sets\n","X_validate, X_train = x_train_full[:500], x_train_full[500:]\n","Y_validate, Y_train = y_train_full[:500], y_train_full[500:]\n","class_names = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n","# Define the model\n","model = keras.models.Sequential([\n","keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)),\n","keras.layers.MaxPooling2D(2),\n","keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n","keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n","keras.layers.MaxPooling2D(2),\n","keras.layers.Flatten(),\n","keras.layers.Dropout(0.5),\n","keras.layers.Dense(64, activation=\"relu\"),\n","keras.layers.Dropout(0.5),\n","keras.layers.Dense(10, activation=\"softmax\")\n","])\n","model.summary()\n","\n","hidden1 = model.layers[1]\n","hidden1_weights = hidden1.get_weights()\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","# Fit the model\n","history = model.fit(x_train, y_train, epochs=5, validation_data=(x_validate, y_validate))"],"metadata":{"id":"VZGnDT9QtUBc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Practical 7 : Write a program to display & plot various performance parameters related to CNN.\n","import matplotlib.pyplot as plt\n","# Assuming you have your model, training data (train_images, train_labels),\n","# and test data (test_images, test_labels) prepared\n","# Train the model\n","history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n","# Visualize accuracy and loss curves\n","plt.plot(history.history['accuracy'], label=\"Accuracy\")\n","plt.plot(history.history['val_accuracy'], label='Val accuracy')\n","plt.plot(history.history['loss'], label='Loss')\n","plt.plot(history.history['val_loss'], label='Val loss')\n","# Customize plot for clarity\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy/Loss')\n","plt.title('Model Training and Validation Performance')\n","plt.grid(True) # Add grid lines for better readability\n","plt.ylim(0, 1) # Set appropriate y-axis limits for accuracy\n","# Evaluate test data performance\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print('Test loss:', test_loss)\n","print('Test accuracy:', test_acc * 100)\n","# Optionally display the plot (if desired)\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"metadata":{"id":"VPeGUR71uqbU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Practical 8 Implementation of CNN to Predict numbers from Number Images.\n","\n","from keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten\n","import matplotlib.pyplot as plt\n","(X_train,Y_train), (X_test, Y_test) =mnist.load_data()\n","plt.imshow(X_train[2])\n","plt.show()\n","\n","print(X_train[0].shape)\n","X_train = X_train.reshape(60000, 28, 28, 1)\n","X_train -= X_train.reshape(60000, 28, 28, 1)\n","X_test = X_test.reshape(10000, 28, 28, 1)\n","\n","Y_train=to_categorical (Y_train)\n","Y_test=to_categorical (Y_test)\n","Y_train[0]\n","print(Y_train[0])\n","\n","model=Sequential()\n","model.add(Conv2D (64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n","model.add(Conv2D (32, kernel_size=3, activation='relu'))\n","model.add(Flatten())\n","model.add(Dense (10, activation='softmax'))\n","model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=[\"accuracy\"])\n","model.fit(X_train,Y_train, validation_data=(X_test,Y_test), epochs=1)\n","print(model.predict(X_test[:4]))\n","print(Y_test[:4])\n","\n"],"metadata":{"id":"u_yIjOxCvCLz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Practical 9 Write a Program to implement RNN\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM\n","from keras.optimizers import Adam\n","# Load and preprocess the dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = X_train.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","# Reshape input data for LSTM\n","X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n","X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n","# Build the model\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(128))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(10, activation='softmax'))\n","# Compile the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))\n","# Evaluate the model\n","model.evaluate(X_test, y_test, verbose=0)"],"metadata":{"id":"u_pOkoWXv7Cf"},"execution_count":null,"outputs":[]}]}